<?xml version="1.0" encoding="UTF-8"?>

<configuration>

    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <!-- Log message format -->
        <encoder>
            <!-- <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern> -->
            <pattern>%d{HH:mm:ss.SSS} %highlight(%-5level) %cyan(%logger{15}) %message%n%xException{5}</pattern>
        </encoder>
    </appender>

    <!-- Appender to write to file -->
    <appender name="FILE"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>log/application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>log/application-log-%d{yyyy-MM-dd}.log.gz
            </fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>

        <encoder>
            <!-- pattern>%d{HH:mm:ss.SSS} TKD [%thread] %-5level %logger{36} - %msg%n</pattern -->
            <pattern>%d{HH:mm:ss.SSS} %highlight(%-5level) %cyan(%logger{15}) %message%n%xException{5}</pattern>
        </encoder>
    </appender>

    <!-- The logger name is typically the Java/Scala package name. This configures
        the log level to log at for a package and its children packages. Levels are:
        TRACE, DEBUG, INFO, WARN, ERROR. -->

    <logger name="org.example.ws" level="INFO" />

    <root level="INFO">
        <appender-ref ref="FILE" />
        <appender-ref ref="STDOUT" />
    </root>

    <!-- This is the kafkaAppender -->
    <!--
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
    -->

    <!-- This is the default encoder that encodes every log message to an utf8-encoded string -->
    <!--
    <encoder
        class="com.github.danielwegener.logback.kafka.encoding.PatternLayoutKafkaMessageEncoder">
        <layout class="net.logstash.logback.layout.LogstashLayout" />
    </encoder>
    <topic>logs</topic>
    <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.RoundRobinKeyingStrategy" />
    <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
    -->

    <!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
    <!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
    <!-- bootstrap.servers is the only mandatory producerConfig -->
    <!--
    <producerConfig>bootstrap.servers=localhost:9092</producerConfig>
    -->
    <!-- this is the fallback appender if kafka is not available. -->
    <!--
        <appender-ref ref="STDOUT" />
    </appender>
    -->

    <!-- Setting the root level of logging to INFO -->
    <!--
    <root level="INFO">
        <appender-ref ref="kafkaAppender" />
        <appender-ref ref="ASYNCFILE" />
        <appender-ref ref="ASYNCSTDOUT" />
    </root>
    -->

    <!-- LogStash Appender -->
    <!--
    <include resource="org/springframework/boot/logging/logback/base.xml"/>

    <appender name="stash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>logstash:5000</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>
    </appender>

    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="stash"/>
    </root>

    <logger name="org.springframework" level="INFO"/>
    <logger name="com.example" level="DEBUG"/>
    -->

</configuration>