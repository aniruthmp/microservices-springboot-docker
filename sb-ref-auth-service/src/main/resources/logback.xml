<?xml version="1.0" encoding="UTF-8"?>

<configuration>

    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <!-- json format -->
        <!--<encoder class="net.logstash.logback.encoder.LogstashEncoder"/>-->

        <encoder>
            <charset>UTF-8</charset>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %highlight(%-5level) %cyan(%logger{36}) %msg%n</pattern>
        </encoder>
    </appender>

    <!-- Appender to write to file -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>./log/application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>./log/application-log-%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>25MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <maxHistory>30</maxHistory>
        </rollingPolicy>

        <!-- Chose either json or standard log format below for logfile -->

        <!-- json format -->
        <!--<encoder class="net.logstash.logback.encoder.LogstashEncoder"/>-->

        <!-- non-json format below -->
        <encoder>
            <charset>UTF-8</charset>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %logger{36} %msg%n</pattern>
        </encoder>
    </appender>

    <!-- The logger name is typically the Java/Scala package name. This configures
        the log level to log at for a package and its children packages. Levels are:
        TRACE, DEBUG, INFO, WARN, ERROR. -->

    <logger name="com.example" level="INFO" />

    <root level="INFO">
        <appender-ref ref="FILE" />
        <appender-ref ref="STDOUT" />
    </root>

    <!-- This is the kafkaAppender -->
    <!--
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
    -->

    <!-- This is the default encoder that encodes every log message to an utf8-encoded string -->
    <!--
    <encoder
        class="com.github.danielwegener.logback.kafka.encoding.PatternLayoutKafkaMessageEncoder">
        <layout class="net.logstash.logback.layout.LogstashLayout" />
    </encoder>
    <topic>logs</topic>
    <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.RoundRobinKeyingStrategy" />
    <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
    -->

    <!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
    <!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
    <!-- bootstrap.servers is the only mandatory producerConfig -->
    <!--
    <producerConfig>bootstrap.servers=localhost:9092</producerConfig>
    -->
    <!-- this is the fallback appender if kafka is not available. -->
    <!--
        <appender-ref ref="STDOUT" />
    </appender>
    -->

    <!-- Setting the root level of logging to INFO -->
    <!--
    <root level="INFO">
        <appender-ref ref="kafkaAppender" />
        <appender-ref ref="ASYNCFILE" />
        <appender-ref ref="ASYNCSTDOUT" />
    </root>
    -->

    <!-- LogStash Appender -->
    <!--
    <include resource="org/springframework/boot/logging/logback/base.xml"/>

    <appender name="stash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>logstash:5000</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>
    </appender>

    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="stash"/>
    </root>

    <logger name="org.springframework" level="INFO"/>
    <logger name="com.example" level="DEBUG"/>
    -->

</configuration>
